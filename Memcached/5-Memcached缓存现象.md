## 缓存雪崩现象
一般由于某个节点失效，导致其他缓存节点的命中率下降，缓存中缺失的数据去数据库中查询，短时间内造成数据库服务器奔溃。

奔溃后有这样的现象，DB数据库down机了，然后重启DB，短期内数据库服务器又被压垮，但缓存的数据更多一些，DB服务器反复多次启动多次，缓存重建完毕，DB才稳定运行。负载

或者由于缓存周期性的失效，比如每6小时失效一次，那么每6个小时就会有一次请求的峰值，严重者会令DB奔溃。

**案例**
一个门户网站

**解决方案**
- key的添加给一个一定范围内的随机值
由于缓存是非常明显的范围内失效，观察视频中的案例能看到负载高峰期时在1个小时内发生，负载高峰时隔6个小时左右，这意味着Memcached是在1个小时内完成数据的缓存，由于key的失效时间高度集中，所以导致的间歇性高峰负载。
在实际操作中我们可以把缓存的失效时间随即设置为3-9小时内，这样不同时失效，就降低了对数据库的负载。

- 将缓存时间调长，半夜跑定时脚本来刷新缓存。
一般情况下，一个网站的访问量会在凌晨1点左右开始降低，1-6点可以认为是一个网站访问量的最低峰。
首先将失效时间放在凌晨这个时间段，那么在白天的时间阶段MySQL数据库服务器就不会奔溃，当凌晨失效的时候，在接近早上的这个时间段，缓存开始缓慢建立，当访问压力大的时候，缓存其实已经发挥作用了，这样就把奔溃的时间段度过去了。
一句话概括：利用凌晨低访问量来缓慢的建立缓存，配合脚本来度过对MySQL服务器的高峰期

## 缓存无底洞现象/Multiget-hole
该想想是facebook提出的，fackbook在2000年的时候，缓存节点达到3000多，缓存数千G的内容，他们发现一个问题，memcached的缓存连接频率/效率降低了，于是增加memcached节点、但是memcached的连接频率依据存在，这种现象被他们称为"无底洞现象"。

**multiget-hole 问题分析**
以访问个人主页举例，用户数据有user-133-name、user-133-height、user-133-age
多个key，当服务器增加的时候，由于采用的一致性哈希算法，133用户的信息也会散落在各个服务器的节点，所以同样是访问个人主页的信息，随着你缓存节点的增多，要连接的节点也增多，对于memcached的连接数，并没有随着节点多而下降，这便是问题的来源。

**multiget-hole解决**
将数据关联度高的数据统合在一起以单独的key进行存储，例如上述的用户数据，
key定义为user-133，值参考MySQL设计成：user:133:age=24,user:133:height=180,user:133:name=zhangsna，我个人感觉设计成json数据存储解析更快。

这样就解决了必须去不同节点获取数据的连接现象了。

## 永久数据被T现象
**现象反应**
网上有人反馈说Memcached数据丢失，明明设置为永久有效，却无辜丢失数据。
我们知道Memcached是惰性删除的，只有在获取数据的时候才会判断是否过期，所以这种现状应该是LRU与廓形删除造成的。

**现象分析**
- 在slab中有永久数据和非永久数据，存储的chunk已经饱和
- 假设客户端一直在get非永久数据，永久数据一直未被get到，处于非活跃状态
- memcached是惰性删除机制，只有在获取的时候才会判断key是否过期，所以当新增一个key的时候，就会把永久数据t出slab中

这就是永久数据被T现象，从概念上来说，这种现象发生的不多，不过还是有的。

**实验**
验证：验证永久数据是否会被t的现象

代码：...
eviction：被踢出的意思

**解决方法**
将永久数据和非永久数据分开放。