吞吐率

吞吐率用于描述服务器的并发能力，它是指单位时间内服务器处理的请求数量，单位是"reqs/s"。

从定义来看，吞吐率描述了服务器在实际运行期间单位时间内处理的请求数，然后一般更关注的是服务器并发处理能力的上限，即单位时间内服务器能够处理的最大请求，即最大吞吐率。



吞吐率的前提包括并发用户数、总请求数和请求资源描述3个条件。



### 并发用户数

并发用户数是指在某一时刻同时向服务器发送请求的用户总数。

在测试中连续发送请求是指发出一个请求收到响应后再发出下一个请求，因此1个用户发送1000次请求与100个用户同时向服务器分别进行10次请求，倆者是不一样，前者在服务器的网卡缓冲区中只有来自该用户的请求，后者在服务器网卡接收缓冲区最多有100个等待处理的请求。

- 实际并发用户数

  即客户端同时存在的用户数量。

- 最大并发连接数

  web服务器所能打开的最大文件描述符数量。

  实际并发用户数可以理解为web服务器当前维护的不同用户的文件描述符总数，当然不是来多少用户就维护多少文件描述符。

  所以实际并发用户数有时候会大于服务器所维护的描述符总数，多出的用户请求会在服务器内核的数据接收缓冲区中等待处理。



### 请求等待时间

对于请求等待时间，需要关注俩个指标：

- 用户平均请求等待时间

  指的是服务器在一定并发用户数的情况下，对于单个用户的服务质量（等待时间）

- 服务器平均请求处理时间

  用于衡量服务器的整体服务质量，它其实是吞吐率的倒数，即单个请求的处理事件。

假设有100个用户同时向服务器发出请求，服务器一般采用多进程或多线程的并发模型，通过多个执行流来同时处理多个并发用户的请求，多执行流的设计体系是轮流交错使用CPU时间片，所以每个执行流的花费时间边长，对于用户的每个请求等待时间必然增加；而对服务器来说如果并发策略得当，每个请求的处理平均时间会减少。



ab.ext测试结果说明

- Concurrency Level

  表示并发用户数

- Time taken for tests

  表示所有请求被处理完成花费的时间。

- Complete requests

  总请求数

- Failed requests

  失败的请求数

- Request per second

  吞吐率，它等于总请求数除以完成请求花费的时间。

  Complete requests / Time taken for tests

- Time per request

  用户平均请求等待时间，等于 总时间 除以 每个用户发出请求的数量

  Time taken for tests / (Complete requests / Concurrency Level)

- Time per request (mean, across all concurrent requests)

  服务器平均处理请求的时间，它等于吞吐率的倒数。

  time taken for tests / Complete requests



- Total transferred

  所有请求的响应数据长度的总和，包括每个HTTP响应头部信息和响应内容数据的长度。

  注：不包括http请求数据的长度。

- HTML transferred

  表示所有请求响应数据中正文数据的总和，即减去了Total transferred中HTTP响应数据头头部信息的长度。



最后部分则描述每个请求处理时间的分布情况，这里每个请求的处理时间是指用户平均请求等待时间。



实践

在性能测试过程中，通过一定量的请求下，测试随着并发用户数的不同，其他指标发生的变化。



影响web服务器性能指标除了服务器配置外就是并发策略了。

并发策略的设计就是在服务器同时处理较多请求的时候，如何合理协调充分的利用CPU计算和I/O操作，使其在较大的并发用户数的情况下提供较高的吞吐率。