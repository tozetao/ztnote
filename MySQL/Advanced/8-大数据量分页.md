## 大数据量分页 ##

### 1. 业务上的优化

### 2. 索引优化
由于索引的查询效率，可以通过id作为分页的划分点来进行截取数据，这种优化方式要满足表记录的完整性，即不能有记录被删除。



### 3. 延迟关联
通过索引覆盖查询出记录的id的集合，再通过id的集合来查询记录。

```sql
select field from table limit 30,10
```
假设每页显示perpage条，当前是第N页，公式为：(N-1) * perpage，
这种分页的查询方式在数据量非常大的时候，效率和速度是非常慢的。

> 效率测试

建立一张1000W条数据量的表

limit 3000000, 10
用时大概2-4秒，这是因为limit是先查询出offset条数据后，跳过offset条数据后再取出10条数据，所以效率是非常低的。

show pfofile for query id;
Sending data，时间主要花费在这里。

> 从业务逻辑上来优化

类似于百度、google，他们在分页的时候最大页数只允许翻到100页左右，超过这个页数则不显示分页数据，这是从业务逻辑上来处理。

一般用户在你网站上只看前几页，并不会查看很多页数后面的数据。

> 索引优化

select id,name from lx_com where id > 5000000 limit 10;

由于索引的查找效率是非常高的，通过id作为分页的划分点再取出10条记录，效率就提升了，但是这种方式有一个问题，因为id是自增的，如果被删除了，那么分页的划分点就是错误的了。

r = (N-1)*10，假设n=9，r=90，但是如果数据是被删除的，那么分页点就是错乱的。

这种用法要求一个前提条件，id是自增且连贯的，数据没有被删除过。

一般来说大网站的数据都是不物理删除的，只做逻辑方面的删除。
照样进行查询，只是现实的时候不要显示逻辑删除的数据

> 非要物理删除，还要用offset精准查询，并不限制用户分页

延迟关联
一般而言是这样做的，通过索引覆盖来进行查询。
select id,name from lx_com limit 5000000,10;
--由于要回行，所以数据非常慢

select id from lx_com limit 500000,10;
-- 只在索引文件上进行查找，相对来说速度会提升
在拿到这10个id后在去查询相对的数据就可以了。

