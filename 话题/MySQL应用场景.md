a：

![ms1](D:\study\repositories\ztnote\problems\images\ms1.png)

b：

kv场景mysql也可以支撑，kv场景优化很容易的，首先构建一个索引库，

key, db_name，table_name，record_id

然后按照key hash分表，key就是手机号或邮箱
 查出来之后再去单条去对应db里面where id in





































其他场景。

a：比如电商几十亿订单数据，用户前台要看，像京东。这个要事实啊

b：我们不分表，技术上来看 分表之后你要解决很多问题，分表对代码复杂度带来了指数级上升，日订单十万 一年也就是3000多万 10年才3亿。

订单的特点是纬度多 又需要永久使用 hash分会对业务有影响 range分对统计有影响，订单没法分啊，left join 就完蛋了。

mysql 单表百亿规模没有感受到压力，单表50亿的情况下 下单还保持住5000/s 的性能



![](D:\study\repositories\ztnote\problems\images\ms.jpg)

如果要分表，为啥是偶数，3\*13，7\*17，我一般这么分,质数,hash我都是无脑质数，之前我专门在百亿级的数据规模上测试过，质数表现会好一点，对于分片来说 不到万不得已不做，新业务直接无脑tidb，分片本质是把数据库层的事情应用层来做 这无论如何都是错误的。



c：3*17是啥黑话？

b：n台物理节点m张表，把订单系统物理独立都比分表好，物理独立之后给128c512G 配置 再读写分离，应该一秒几万单没有问题。

分表意味着代码基本大面积重写，这比切换到tidb都还费事。

tidb再数据量超过10亿行的时候就不比mysql慢了，那为啥不考虑tidb，tidb是分布式，部署一套生产可用的tidb至少64c128g资源。

订单没有热点数据，数据库处理麻烦的点在热点数据

c：0.36 亿数据，需要的单机配置就很高了吧？这个堆单机配置吗

b：从应用层压测，一秒压测1000 单。几天时间就到这个量

c：jmeter 么

b：测数据库有啥意思

要看自己的sql烂不烂，比如那种 没有where的count，newsql领域你们值得调研，不止tidb一个，终结一下分表话题

在这个时刻来看 我作为一个分库分表的专家来看就是不要去分库分表，我参与过好几个国产分表分库中间件的开发，用c编写得atlas 和用go编写得的kingshared 还有没有开源过的oneproxy